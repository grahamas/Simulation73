#+PROPERTY: header-args :results output :session *julia* :noweb yes
#+OPTIONS: title:nil author:nil date:nil toc:nil
#+LATEX_CLASS: article
#+LATEX_CLASS_OPTIONS: [12pt]
#+LATEX_HEADER_EXTRA: \input{\string~/Dropbox/Tex/standard_preamble.tex}
#+AUTHOR: Graham Smith
#+EMAIL: grahamas@gmail.com
#+TITLE: Fitting the Wilson-Cowan Integro-Differential Equations
#+LATEX_HEADER: \input{\string~/Dropbox/Tex/math_preamble.tex}


* Introduction

Here I will simulate the spatially one-dimensional Wilson-Cowan equations as described in
*************** TODO Cite Wilson, Cowan 1973 paper
*************** END

*************** TODO Figure out citations in org-mode
*************** END

using the Julia.

* Equations

First, let's specify the equations we will be simulating:

\[\begin{align}
\tau_E \partial_t E(x,t) &= -\alpha_E E(x,t) + \beta_E (1 - E(x,t)) \cS_E \left( W_{EE}(X) \conv E(x,t) + W_{EI}(X) \conv I(x,t) + P_E(x,t)\right)\\
\tau_I \partial_t I(x,t) &= -\alpha_I I(x,t) + \beta_I (1 - I(x,t)) \cS_I \left( W_{IE}(X) \conv E(x,t) +  W_{II}(X) \conv I(x,t) + P_I(x,t)\right)
\end{align}\]
*************** TODO Make nonlinearity a mathop
*************** END


though in practice we discretize and turn the convolution into a matrix multiplication (the latter a decision made for the author's understanding rather than for any computational considerations). Suppose we discretize space into $M$ points, so that we can think of $E(\cdot, t)$ as a $M\times 1$ vector. Define $\bA(t)$ as the vertical concatenation of $E(\cdot, t)$ on top of $I(\cdot, t)$ such that $\bA(t)$ is a $2M \times 1$ vector.[fn:1]  Then the equation we actually simulate is

\[\begin{align}
\btau \odot \Delta \bA(t^+) &= -\balpha \odot \bA(t) + \bbeta \odot (1 - \bA(t)) \cS \left( \bW \bA(t) + \bP(t)\right)
\end{align}\]

where $\odot$ is the Hademard (element-wise) product of an appropriately expanded[fn:2] parameter vector, e.g. so that in the first instance, each element of $\bA$ corresponding to an element of $E$ is multiplied by $\tau_E$, and similarly for $I$.

* Simulation
** Overview
The code will proceed as follows

#+BEGIN_SRC julia :noweb no-export :results silent :tangle yes
<<load-modules>>
<<parameters-loader>>
<<wc73-definition>>
<<wc73-solver>>
<<wc73-analysis>>
<<run-wc73-trial>>
#+END_SRC

See the appendix for helper functions, including parameter loading.

** Imports

#+BEGIN_SRC julia :noweb-ref load-modules :results silent
  using ParameterizedFunctions
  import ParameterizedFunctions: AbstractParameterizedFunction

  using Parameters
  import JSON

  using TensorOperations

  using DifferentialEquations

  using Plots; gr()
#+END_SRC

** Define WilsonCowan73

I will relegate the sigmoid and input functions to the appendix. Suffice to say, the sigmoid is rectified and normed, and the input function is a step function centered at $x=0$.

#+BEGIN_SRC julia :noweb no-export :noweb-ref wc73-definition :results silent
  <<define-sigmoid>>
  <<define-stimulus>>
  <<define-connectivity>>
  <<define-wc73-types>>
  <<define-wc73-constructor>>
  <<define-wc73-differential>>
#+END_SRC

#+BEGIN_SRC julia :noweb-ref define-wc73-types
  const NumType = Float64
  const TimeType = NumType
  const PopulationParam = RowVector{NumType}
  const InteractionParam = Array{NumType}
  const SpaceState = Array{NumType,2}
  @with_kw struct WilsonCowan73 <: AbstractParameterizedFunction{true}
    # Explict fields in parameter file
    # May also be given as LaTeX command (e.g. alpha for α)
      α::PopulationParam     # Weight on homeostatic term
      β::PopulationParam     # Weight on nonlinear term
      τ::PopulationParam     # Time constant
      a::PopulationParam     # Sigmoid steepness
      θ::PopulationParam     # Sigmoid translation
      r::PopulationParam     # Refractory period multiplier
    # Other fields in parameter file include
    # :time => {[:N], :extent}
    # :space => {:N, :extent}
    # :stimulus => {:weight, :duration, :strength}
    # :connectivity => {:amplitudes, :spreads}
    # Constructed fields
      W::InteractionParam    # Tensor interaction multiplier
      stimulus_frame::SpaceState  # Vector giving the "on" input
      stimulus_duration::TimeType # Scalar input duration (time units)
      stimulus_steepness::NumType
  end

#+END_SRC

#+BEGIN_SRC julia :noweb-ref define-wc73-constructor

    function WilsonCowan73(p)
	n_pops = length(p[:r])

	space_params = pop!(p, :space)
	xs = make_mesh(space_params)

	stimulus_params = pop!(p, :stimulus)
	p[:stimulus_duration] = stimulus_params[:duration]
	p[:stimulus_steepness] = stimulus_params[:steepness]
	p[:stimulus_frame] = make_stimulus_frame(xs, n_pops,
						 stimulus_params[:width], stimulus_params[:strength],
						 stimulus_params[:steepness])

	connectivity_params = pop!(p, :connectivity)
	p[:W] = sholl_tensor(xs, connectivity_params[:amplitudes], connectivity_params[:spreads])

	return WilsonCowan73(; p...)
    end

#+END_SRC

#+BEGIN_SRC julia :noweb-ref define-wc73-differential

    (p::WilsonCowan73)(t::TimeType,A::SpaceState,dA::SpaceState) = begin
	# Use dA as intermediate variable for tensor op since it is preallocated
	@tensor dA[x_tgt, pop_tgt] = p.W[x_tgt, x_src, pop_tgt, pop_src] * A[x_src, pop_src]
	@. dA = (-p.α * A +
		 p.β * (1 - A) * @sigmoid(dA + @step_stimulus(t,
							      p.stimulus_frame,
							      p.stimulus_duration,
							      p.stimulus_steepness),
					  p.a, p.θ)
		 ) / p.τ
    end
#+END_SRC

** WilsonCowan73 Solver

#+BEGIN_SRC julia :noweb-ref wc73-solver

  function solve_WilsonCowan73(wc73_fn::WilsonCowan73, solver_params::Dict)
      # Define problem
      u0 = similar(wc73_fn.stimulus_frame, NumType)
      u0 .= 0
      tspan = (0.0, pop(solver_params, :T))
      prob = ODEProblem(wc73_fn, u0, tspan)

      # Solve problem
      soln = solve(prob; solver_params...)

      return soln
  end

#+END_SRC

** Analysis and Runner
This code currently only plots.
#+BEGIN_SRC julia :noweb-ref wc73-analysis

  function solution_gif(soln; root="", filename="solution.gif", disable=0, subsample=1, fps=15)
      if disable
	  return
      end
      max_activity = maximum(soln, (1,2,3))[1] # I don't know why this index is here.
      min_activity = minimum(soln, (1,2,3))[1]
      anim = @animate for i in 1:length(soln.t)
	  plot([soln[:,1,i], soln[:,2,i]], ylim=(min_activity, max_activity), title="t=$(soln.t[i])")
      end
      save_path = joinpath(root, filename)
      if !(isfile(save_path))
	  gif(anim, save_path, fps=fps)
      else
	  warn("Tried to write existing gif $(save_path).")
      end
  end

  function analyse_WilsonCowan73_solution(soln, analyses)
      root = analyses[:root]
      solution_gif(soln; root=root, analyses[:activity_gif]...)
  end


  function run_WilsonCowan73_trial(json_filename::String)
      params = load_WilsonCowan73_parameters(json_filename)
      soln = solve_WilsonCowan73(WilsonCowan73(params[:model]), params[:solver])
      analyse_WilsonCowan73_solution(soln, params[:analysis])
  end

#+END_SRC

** Run Trial

Then the solution is as simple as
#+BEGIN_SRC julia :noweb-ref run-wc73-trial
run_WilsonCowan73_trial("jl_replicate_neuman.json")
#+END_SRC

#+RESULTS:
: INFO: Saved animation to /home/grahams/Dropbox/Research/simulation-73/solution.gif
: Plots.AnimatedGif("/home/grahams/Dropbox/Research/simulation-73/solution.gif")

* Appendix
** Parameter file reading
Because I originally wrote this in Python, the parameter files are JSON.
#+BEGIN_SRC julia :noweb-ref parameters-loader :results silent
  function convert_py(val)
      return float(val)
  end

  function parse_pyarray(a)
      if isa(a[1], Array)
	  return convert_py(hcat(a...))'
      else
	  return convert_py(vcat(a...))'
      end
  end

  function parse_pydict(d)
      function parse_pykey(k)
	  unicode_dct = Dict(:alpha=>:α, :beta=>:β, :tau=>:τ, :theta=>:θ)
	  k_sym = Symbol(k)
	  if k_sym in keys(unicode_dct)
	      return unicode_dct[k_sym]
	  else
	      return k_sym
	  end
      end

      function parse_pyvalue(v)
	  if isa(v, Dict)
	      return parse_pydict(v)
	  elseif isa(v, Array)
	      # Assumes arrays only contain numbers
	      return parse_pyarray(v)
	  else
	      return convert_py(v)
	  end
      end

      return Dict(parse_pykey(k) => parse_pyvalue(v) for (k,v) in d)
  end


  function load_WilsonCowan73_parameters(json_filename::String)
      # Parse JSON with keys as symbols.
      param_dct = (parse_pydict ∘ JSON.parsefile)(json_filename)
      return param_dct
  end

#+END_SRC

#+RESULTS:
#+begin_example
convert_py (generic function with 1 method)

parse_pykey (generic function with 1 method)

parse_pyvalue (generic function with 1 method)

parse_pyarray (generic function with 1 method)

parse_py_dict (generic function with 1 method)

load_WilsonCowan73_parameters (generic function with 1 method)
#+end_example

** Sigmoid

The sigmoid function is defined
\[\begin{align}
\sigmoid(x) = \frac{1}{1 + \exp(-a(x - \theta))}
\end{align}\]
where $a$ describes the slope's steepness and $\theta$ describes translation of the slope's center away from zero.

The current definition uses a macro. It is not clear that this is necessary, nor even advisable. However, the ParameterizedFunction automatically calculates useful quantities like the Jacobian, including with respect to the parameters themselves, and I thought I'd see if this works better. Initially I was using a provided macro that didn't seem to like function calls, so this macro was necessary. Now I doubt it's necessary and I'll probably run some tests to see if there's any performance difference in the DifferentialEquations solve.

#+BEGIN_SRC julia :noweb-ref define-sigmoid :results silent
  macro simple_sigmoid(x, a, theta)
      return :(@. 1 / (1 + exp(-$(esc(a)) * ($(esc(x)) - $(esc(theta))))))
  end

  macro sigmoid(x, a, theta)
       return :(@. max(0, @simple_sigmoid($(esc(x)), $(esc(a)), $(esc(theta))) - @simple_sigmoid(0, $(esc(a)), $(esc(theta)))))
  end

  function simple_sigmoid_fn(x, a, theta)
      return @simple_sigmoid(x, a, theta)
  end

  function sigmoid_fn(x, a, theta)
      return @sigmoid(x, a, theta)
  end
#+END_SRC

** Connectivity

We use an exponential connectivity function, inspired both by Sholl's experimental work, and by certain theoretical considerations.

#+BEGIN_SRC julia :noweb-ref define-connectivity :results silent
  function make_mesh(dim_params)
      extent = dim_params[:extent]
      N = dim_params[:N]

      return linspace(-extent, extent, N)
  end


  function distance_matrix(xs)
      # also aka Hankel, but that method isn't working in SpecialMatrices
      distance_mx = zeros(eltype(xs), length(xs), length(xs))
      for i in range(1, length(xs))
	  distance_mx[:, i] = abs.(xs - xs[i])
      end
      return distance_mx'
  end

  function sholl_matrix(amplitude, spread, dist_mx, step_size)
      conn_mx = @. amplitude * step_size * exp(
	  -abs(dist_mx / spread)
      ) / (2 * spread)
      return conn_mx
  end

  function sholl_tensor(xs, W, Σ)
      N_x = length(xs)
      N_pop = size(W)[1]
      conn_tn = zeros(N_x, N_x, N_pop, N_pop)
      for tgt_pop in range(1,N_pop)
	  for src_pop in range(1,N_pop)
	      conn_tn[:, :, tgt_pop, src_pop] .= sholl_matrix(W[tgt_pop, src_pop],
			    Σ[tgt_pop, src_pop], distance_matrix(xs), step(xs))
	  end
      end
      return conn_tn
  end

#+END_SRC

** Stimulus

*************** TODO Experiment with constant steep_a, both numerically and syntactically
*************** END

As mentioned above, the ParameterizedFunction does some automatic differentiation. In deference to this (though without testing in the first place...) I've replaced the usual heaviside step function with the sigmoid approximation. A value of 10 was chosen arbitrarily as a relatively steep slope.

#+BEGIN_SRC julia :noweb-ref define-stimulus :results silent
  macro step_stimulus(t_sym, on_frame_sym, duration_sym, steepness_sym)
     return :(@. $(esc(on_frame_sym)) * (1-@simple_sigmoid($(esc(t_sym)), $(esc(steepness_sym)), $(esc(duration_sym)))))
  end

  function make_stimulus_frame(xs, n_pops, width, strength, steepness)
      one_pop_frame = @. strength * (simple_sigmoid_fn(xs, steepness, -width/2) - simple_sigmoid_fn(xs, steepness, width/2))
      return repeat(one_pop_frame, outer=(1,n_pops))
  end
#+END_SRC

#+BEGIN_SRC julia :noweb-ref visualise-step-stimulus :results graphics
  let N_x=500, x_extent=3, width=2, strength=3, duration=4, N_t=700, t_extent=7
      global xs = linspace(-x_extent, x_extent, N_x)
      global on_frame = make_input_frame(xs, width, strength)
      global ts = linspace(0, t_extent, N_t)
      global val = zeros(Float64, N_x, N_t)
      for (i,t) in enumerate(ts)
	  val[:,i] = @step_input(t, on_frame, duration)
      end
  end
  x_grid = repeat(xs, outer=(1, length(ts)));
  t_grid = repeat(ts', outer=(length(xs),1));
  #pyplot()
  #Plots.surface(x_grid, t_grid, val)
  gr()
  Plots.surface(val)
#+END_SRC

#+RESULTS:
:
:
:
:
:
: Plots.GRBackend()

* Footnotes

[fn:2] Under the tensor notation, this is merely broadcasting.

[fn:1] It will be more natural (and likely extensible) to concatenate along the second dimension, as done in the previous Python implementation. Here I restrict myself to vertical concatenation to avoid muddling things with the introduction of tensor multiplication and Einstein notation.
